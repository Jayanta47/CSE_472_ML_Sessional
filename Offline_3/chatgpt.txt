import numpy as np

class GaussianMixtureModel:
    def __init__(self, n_components):
        self.n_components = n_components
        self.weights = np.random.rand(n_components)
        self.weights /= np.sum(self.weights)
        self.means = np.random.rand(n_components)
        self.covariances = np.array([np.eye(1) for _ in range(n_components)])

    def fit(self, X, max_iter=100):
        for i in range(max_iter):
            # E-step
            responsibilities = self._responsibilities(X)
            # M-step
            self._maximize(X, responsibilities)

    def _responsibilities(self, X):
        n_samples, _ = X.shape
        responsibilities = np.zeros((n_samples, self.n_components))
        for k in range(self.n_components):
            responsibilities[:, k] = self.weights[k] * self._pdf(X, self.means[k], self.covariances[k])
        responsibilities /= np.sum(responsibilities, axis=1, keepdims=True)
        return responsibilities

    def _maximize(self, X, responsibilities):
        n_samples, _ = X.shape
        for k in range(self.n_components):
            weight = np.mean(responsibilities[:, k])
            mean = np.sum(responsibilities[:, k] * X, axis=0) / np.sum(responsibilities[:, k])
            covariance = np.dot((responsibilities[:, k] * (X - mean)).T, (X - mean)) / np.sum(responsibilities[:, k])
            self.weights[k] = weight
            self.means[k] = mean
            self.covariances[k] = covariance

    def _pdf(self, X, mean, covariance):
        n_samples, _ = X.shape
        return (1. / ((2 * np.pi)**0.5 * np.linalg.det(covariance)**0.5) *
                np.exp(-0.5 * np.sum(np.dot(X - mean, np.linalg.inv(covariance)) * (X - mean), axis=1)))

